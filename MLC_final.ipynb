{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYCweO9Om5QB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models # ResNet, VGG\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import cv2\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit # ensure balanced representation of all labels\n",
        "from sklearn.metrics import average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wb1chDBm5QC",
        "outputId": "5925eecc-8848-4f35-9aae-48aa2dd894fe"
      },
      "outputs": [],
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHFi_KD3m5QC"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image, target_size):\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    mean = np.array([0.485, 0.456, 0.406]) # Channel-wise normalization (ImageNet statistics)\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = (image - mean) / std\n",
        "\n",
        "    image = np.transpose(image, (2, 0, 1)) # HWC -> CHW\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_dir = 'Datasets/DFC-15_MLC'\n",
        "target_size = (256, 256)\n",
        "\n",
        "images_path = os.path.join(dataset_dir, \"images\")\n",
        "labels_csv_path = os.path.join(dataset_dir, \"multilabel.csv\")\n",
        "\n",
        "df = pd.read_csv(labels_csv_path)\n",
        "image_filenames = df[\"filename\"].values\n",
        "multi_labels = df.iloc[:, 1:].values\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for idx, filename in enumerate(image_filenames):\n",
        "    img_path = os.path.join(images_path, f\"{str(filename)}.png\")\n",
        "    image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = preprocess_image(image, target_size)\n",
        "\n",
        "    images.append(image)\n",
        "    labels.append(multi_labels[idx])\n",
        "\n",
        "all_images = np.array(images, dtype=np.float32)\n",
        "all_labels = np.array(labels, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labeled_ratio = 0.25\n",
        "test_ratio = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_samples = all_images.shape[0]\n",
        "num_classes = all_labels.shape[1]\n",
        "\n",
        "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=test_ratio, random_state=42)\n",
        "train_idx, test_idx = next(msss.split(all_images, all_labels))\n",
        "train_images, test_images = all_images[train_idx], all_images[test_idx]\n",
        "train_labels, test_labels = all_labels[train_idx], all_labels[test_idx]\n",
        "\n",
        "msss_labeled = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=1-labeled_ratio, random_state=42)\n",
        "labeled_idx, unlabeled_idx = next(msss_labeled.split(train_images, train_labels))\n",
        "\n",
        "labeled_images = train_images[labeled_idx]\n",
        "labeled_images_labels = train_labels[labeled_idx]\n",
        "unlabeled_images = train_images[unlabeled_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZpVq8Mdm5QD",
        "outputId": "ac0b384b-492b-457d-d353-49eefda335cb"
      },
      "outputs": [],
      "source": [
        "print(f\"Training: {len(train_images)}, Testing: {len(test_images)}\")\n",
        "print(f\"Labeled: {len(labeled_images)}, Unlabeled: {len(unlabeled_images)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxU4r4v7m5QD"
      },
      "outputs": [],
      "source": [
        "def extract_features(images, feature_extractor, batch_size=128):\n",
        "\n",
        "    feature_extractor.eval() # Disables dropout and batch normalization updates\n",
        "    feature_extractor = feature_extractor.to(device)\n",
        "\n",
        "    image_tensors = torch.FloatTensor(images) # Images to PyTorch tensors\n",
        "    dataset = TensorDataset(image_tensors)\n",
        "    dataloader = DataLoader(dataset, batch_size, shuffle=False) # Preserves original order\n",
        "\n",
        "    features = []\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in dataloader:\n",
        "            batch_images = batch[0].to(device)\n",
        "            batch_features = feature_extractor(batch_images)\n",
        "\n",
        "            if batch_features.dim() == 4:  # 4D tensor (batch_size, feature_dim, 1, 1) -> (batch_size, feature_dim)\n",
        "                batch_features = batch_features.view(batch_features.size(0), -1)\n",
        "            elif batch_features.dim() == 2:  # 2D tensor (batch_size, feature_dim)\n",
        "                pass\n",
        "\n",
        "            features.append(batch_features.cpu().numpy())\n",
        "    return np.vstack(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AgbFeskm5QD",
        "outputId": "40255779-e200-455a-c35d-f560374e89ae"
      },
      "outputs": [],
      "source": [
        "model_resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "model_resnet50.fc = nn.Linear(model_resnet50.fc.in_features, num_classes)\n",
        "\n",
        "# model_efficientnet_b2 = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.IMAGENET1K_V1)\n",
        "# model_efficientnet_b2.classifier[1] = nn.Linear(model_efficientnet_b2.classifier[1].in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = model_efficientnet_b2.to(device)\n",
        "model=model_resnet50.to(device)\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    torch.tensor(labeled_images).float(),\n",
        "    torch.tensor(labeled_images_labels).float()\n",
        ")\n",
        "\n",
        "print(f\"Image tensor shape: {train_dataset.tensors[0].shape}\") # Shape: [N, 3, H, W]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "LgvDKe7Bm5QD",
        "outputId": "e51a5c43-df7a-4967-cd9c-1cf124f7d653"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4) # Update model weights\n",
        "criterion = nn.BCEWithLogitsLoss() # Sigmoid layer + binary cross-entropy loss: Measures the difference between predicted probabilities and true binary labels\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "epochs=20\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() # Clears old gradients\n",
        "        output_labels = model(inputs)\n",
        "        loss = criterion(output_labels, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} loss: {epoch_loss:.4f}\")\n",
        "\n",
        "feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "feature_extractor=feature_extractor.to(device)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, epochs+1), losses, marker='o', linestyle='-', color='b')\n",
        "plt.title('Training Loss Curve (Cross Entropy Loss)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(range(1, epochs+1))\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_H2JcUOm5QD",
        "outputId": "60af792a-be7c-493f-b544-3452d5f1e801"
      },
      "outputs": [],
      "source": [
        "labeled_images_features = extract_features(labeled_images, feature_extractor)\n",
        "unlabeled_images_features = extract_features(unlabeled_images, feature_extractor)\n",
        "test_images_features = extract_features(test_images, feature_extractor)\n",
        "\n",
        "print(f\"Labeled features shape: {labeled_images_features.shape}\")\n",
        "print(f\"Unlabeled features shape: {unlabeled_images_features.shape}\")\n",
        "print(f\"Test features shape: {test_images_features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrxxaWYvm5QE"
      },
      "outputs": [],
      "source": [
        "def calculate_variance(node_features, node_labels, w):\n",
        "    # Label Variance (Gini impurity)\n",
        "    label_var = 0.0\n",
        "    labeled_mask = ~np.isnan(node_labels).any(axis=1)\n",
        "    if np.sum(labeled_mask) > 0:\n",
        "        labeled_y = node_labels[labeled_mask]\n",
        "        n_labels = labeled_y.shape[1]\n",
        "        gini_scores = []\n",
        "        for label_idx in range(n_labels):\n",
        "            p = np.mean(labeled_y[:, label_idx])\n",
        "            gini = 2*p*(1-p)\n",
        "            gini_scores.append(gini)\n",
        "        label_var = np.mean(gini_scores)\n",
        "    else:\n",
        "        label_var = 0  # No labeled data in this node\n",
        "\n",
        "    # Feature Variance\n",
        "    feature_var = np.var(node_features, axis=0, ddof=0).mean()\n",
        "    return w * label_var + (1 - w) * feature_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_pct(X, y, depth=0, max_depth=5, min_samples_split=2, w=1, parent_prototype=None):\n",
        "    node_prototype = None\n",
        "    labeled_mask = ~np.isnan(y).any(axis=1)\n",
        "    if np.sum(labeled_mask) > 0:\n",
        "        node_prototype = np.nanmean(y[labeled_mask], axis=0)\n",
        "    elif parent_prototype is not None:\n",
        "        node_prototype = parent_prototype\n",
        "    else:\n",
        "        node_prototype = np.zeros(y.shape[1])\n",
        "    \n",
        "    if depth >= max_depth or len(y) < min_samples_split:\n",
        "        return {'type': 'leaf', 'prediction': node_prototype}\n",
        "\n",
        "    best_split = None\n",
        "    best_score = float('inf')\n",
        "    best_split_idx = None\n",
        "\n",
        "    n_features = X.shape[1]\n",
        "    feature_subset_size = max(1, int(np.sqrt(n_features)))\n",
        "    feature_indices = np.random.choice(n_features, feature_subset_size, replace=False)\n",
        "    \n",
        "    for feature_idx in feature_indices:\n",
        "        feature_values = X[:, feature_idx]\n",
        "        \n",
        "        if len(np.unique(feature_values)) > 10:\n",
        "            percentiles = np.percentile(feature_values, [25, 50, 75])\n",
        "            split_candidates = percentiles\n",
        "        else:\n",
        "            split_candidates = np.unique(feature_values)\n",
        "        \n",
        "        for split_val in split_candidates:\n",
        "            left_mask = feature_values <= split_val\n",
        "            right_mask = ~left_mask\n",
        "            \n",
        "            if np.sum(left_mask) < min_samples_split or np.sum(right_mask) < min_samples_split:\n",
        "                continue\n",
        "                \n",
        "            left_var = calculate_variance(X[left_mask], y[left_mask], w) * np.sum(left_mask)\n",
        "            right_var = calculate_variance(X[right_mask], y[right_mask], w) * np.sum(right_mask)\n",
        "            total_var = (left_var + right_var) / len(y)\n",
        "            \n",
        "            if total_var < best_score:\n",
        "                best_score = total_var\n",
        "                best_split = split_val\n",
        "                best_split_idx = feature_idx\n",
        "                \n",
        "    if best_split is None:\n",
        "        return {'type': 'leaf', 'prediction': node_prototype}\n",
        "        \n",
        "    left_mask = X[:, best_split_idx] <= best_split\n",
        "    right_mask = ~left_mask\n",
        "    \n",
        "    node = {\n",
        "        'type': 'node',\n",
        "        'feature_idx': best_split_idx,\n",
        "        'threshold': best_split,\n",
        "        'prototype': node_prototype,  # Store the prototype at each node\n",
        "        'left': build_pct(X[left_mask], y[left_mask], depth+1, max_depth, min_samples_split, w, node_prototype),\n",
        "        'right': build_pct(X[right_mask], y[right_mask], depth+1, max_depth, min_samples_split, w, node_prototype)\n",
        "    }\n",
        "    return node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_pct_forest(X, y, n_estimators, max_depth, w):\n",
        "    min_samples_split = 2\n",
        "    bootstrap = True # bootstrap sampling (random sampling with replacement)\n",
        "    forest = []\n",
        "    n_samples = X.shape[0]\n",
        "\n",
        "    for _ in tqdm(range(n_estimators), desc=\"Building PCT Forest\"):\n",
        "        if bootstrap:\n",
        "            indices = np.random.choice(n_samples, n_samples, replace=True)\n",
        "            X_bootstrap = X[indices]\n",
        "            y_bootstrap = y[indices]\n",
        "        else:\n",
        "            X_bootstrap = X\n",
        "            y_bootstrap = y\n",
        "\n",
        "        tree = build_pct(X_bootstrap, y_bootstrap, max_depth=max_depth, min_samples_split=min_samples_split, w=w)\n",
        "        forest.append(tree)\n",
        "        \n",
        "    return forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWWCKb99m5QE"
      },
      "outputs": [],
      "source": [
        "def predict_pct(tree, X, num_classes):\n",
        "    if not tree:\n",
        "        return np.zeros((X.shape[0], num_classes))\n",
        "\n",
        "    if tree['type'] == 'leaf':\n",
        "        predictions = np.tile(tree['prediction'], (X.shape[0], 1))\n",
        "        nan_mask = np.isnan(predictions).any(axis=1)\n",
        "        if np.any(nan_mask) and 'prototype' in tree:\n",
        "            predictions[nan_mask] = tree['prototype']\n",
        "        return predictions\n",
        "\n",
        "    predictions = np.zeros((X.shape[0], num_classes))\n",
        "    left_mask = X[:, tree['feature_idx']] <= tree['threshold']\n",
        "    right_mask = ~left_mask\n",
        "\n",
        "    if np.any(left_mask):\n",
        "        predictions[left_mask] = predict_pct(tree['left'], X[left_mask], num_classes)\n",
        "    if np.any(right_mask):\n",
        "        predictions[right_mask] = predict_pct(tree['right'], X[right_mask], num_classes)\n",
        "\n",
        "    nan_mask = np.isnan(predictions).any(axis=1)\n",
        "    if np.any(nan_mask) and 'prototype' in tree:\n",
        "        predictions[nan_mask] = np.tile(tree['prototype'], (np.sum(nan_mask), 1))\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def post_process_forest(forest, X_labeled, y_labeled):    \n",
        "    if len(X_labeled) == 0:\n",
        "        return forest\n",
        "    \n",
        "    # Build a nearest neighbors model on the labeled data\n",
        "    nn_model = NearestNeighbors(n_neighbors=1)\n",
        "    nn_model.fit(X_labeled)\n",
        "    \n",
        "    def fix_nan_nodes(node):\n",
        "        if node is None or not isinstance(node, dict):\n",
        "            return\n",
        "            \n",
        "        # If this is a leaf node with NaN predictions\n",
        "        if node['type'] == 'leaf' and (np.isnan(node['prediction']).any() or node['prediction'].sum() == 0):\n",
        "            # Create a dummy example to find nearest labeled sample\n",
        "            dummy_X = np.zeros((1, X_labeled.shape[1]))\n",
        "            if 'sample_indices' in node and len(node['sample_indices']) > 0:\n",
        "                # If we stored sample indices, use the mean feature vector\n",
        "                dummy_X[0] = np.mean(X_labeled[node['sample_indices']], axis=0)\n",
        "                \n",
        "            distances, indices = nn_model.kneighbors(dummy_X)\n",
        "            node['prediction'] = y_labeled[indices[0][0]]\n",
        "            \n",
        "        if 'left' in node:\n",
        "            fix_nan_nodes(node['left'])\n",
        "        if 'right' in node:\n",
        "            fix_nan_nodes(node['right'])\n",
        "    \n",
        "    for tree in forest:\n",
        "        fix_nan_nodes(tree)\n",
        "        \n",
        "    return forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6fTUad6m5QF"
      },
      "outputs": [],
      "source": [
        "def predict_pct_forest(forest, X, num_classes):\n",
        "    predictions = []\n",
        "    for tree in forest:\n",
        "        tree_preds = predict_pct(tree, X, num_classes)\n",
        "        \n",
        "        if np.isnan(tree_preds).any():\n",
        "            tree_preds = np.nan_to_num(tree_preds, nan=0.0)\n",
        "            \n",
        "        predictions.append(tree_preds)\n",
        "\n",
        "    avg_predictions = np.mean(np.array(predictions), axis=0)\n",
        "    return avg_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_combined = np.vstack((labeled_images_features, unlabeled_images_features))\n",
        "y_combined = np.vstack((labeled_images_labels, np.full((unlabeled_images_features.shape[0], num_classes), np.nan)))\n",
        "X_labeled = labeled_images_features\n",
        "y_labeled = labeled_images_labels\n",
        "\n",
        "num_classes = y_combined.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_score = -np.inf\n",
        "best_w = 1.0\n",
        "\n",
        "w_values = []\n",
        "mean_scores = []\n",
        "\n",
        "for w in tqdm(np.arange(0, 1.1, 0.1), desc=\"Optimizing w\"):\n",
        "    fold_scores = []\n",
        "    \n",
        "    kf = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.3)\n",
        "    splits = kf.split(X_labeled, y_labeled)\n",
        "\n",
        "    for train_idx, val_idx in splits:\n",
        "        X_train, X_val = X_labeled[train_idx], X_labeled[val_idx]\n",
        "        y_train, y_val = y_labeled[train_idx], y_labeled[val_idx]\n",
        "\n",
        "        # Add unlabeled data with dummy labels\n",
        "        X_train_full = np.vstack((X_train, unlabeled_images_features))\n",
        "        y_train_full = np.vstack((y_train, np.full((unlabeled_images_features.shape[0], num_classes), np.nan)))\n",
        "\n",
        "        tree = build_pct(X_train_full, y_train_full, max_depth=5, w=w)\n",
        "\n",
        "        # Validate on labeled validation set\n",
        "        y_pred = predict_pct(tree, X_val, num_classes)\n",
        "        score = average_precision_score(y_val, y_pred, average='micro')\n",
        "        fold_scores.append(score)\n",
        "\n",
        "    mean_score = np.mean(fold_scores)\n",
        "    w_values.append(w)\n",
        "    mean_scores.append(mean_score)\n",
        "\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_w = w\n",
        "\n",
        "print(f\"Optimal w: {best_w:.1f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(w_values, mean_scores, marker='o', linestyle='-', color='b', label='Mean AUPRC Score')\n",
        "plt.axvline(best_w, color='r', linestyle='--', label=f'Best w = {best_w:.1f}')\n",
        "plt.xlabel('w')\n",
        "plt.ylabel('Mean Score (AUPRC)')\n",
        "plt.title('Optimization of w')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_w=0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ssl_forest = build_pct_forest(\n",
        "    X_combined, \n",
        "    y_combined, \n",
        "    n_estimators=1, \n",
        "    max_depth=10, \n",
        "    w=best_w\n",
        ")\n",
        "ssl_forest = post_process_forest(ssl_forest, labeled_images_features, labeled_images_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_ssl = predict_pct_forest(ssl_forest, test_images_features, num_classes)\n",
        "micro_auprc = average_precision_score(test_labels, y_pred_ssl, average='micro')\n",
        "macro_auprc = average_precision_score(test_labels, y_pred_ssl, average='macro')\n",
        "\n",
        "print(\"\\nFinal Results:\")\n",
        "print(f\"Micro-AUPRC: {micro_auprc:.4f}, Macro-AUPRC: {macro_auprc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_values = [1, 5, 10, 25]\n",
        "auprc_values = {\n",
        "    \"SSL-RForest\": ([84.69, 93.72, 95.58, 97.03]),\n",
        "    \"SL-RForest\": ([78.23, 91.07, 94.98, 96.5]),\n",
        "    \"SSL-PCT\": ([52.35, 66.69, 73.73, 82.27]),\n",
        "    \"SL-PCT\": ([46.80, 60.66, 68.24, 80.56])\n",
        "}\n",
        "\n",
        "styles = {\n",
        "    \"SSL-RForest\": (\"black\", \"d\", \"-.\"),\n",
        "    \"SL-RForest\": (\"blue\", \"*\", \"-.\"),\n",
        "    \"SSL-PCT\": (\"green\", \"o\", \"-.\"),\n",
        "    \"SL-PCT\": (\"red\", \"s\", \"-.\")\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(7, 3.5))\n",
        "for key, means in auprc_values.items():\n",
        "    color, marker, linestyle = styles[key]\n",
        "    plt.errorbar(N_values, means, fmt=marker, linestyle=linestyle, \n",
        "                 color=color, capsize=3, label=key)\n",
        "\n",
        "plt.title(\"DFC-15 (MLC), EfficientNetB2\")\n",
        "plt.xlabel(\"N (%)\", fontsize=12)\n",
        "plt.ylabel(\"AUPRC\", fontsize=12)\n",
        "plt.xticks(N_values)\n",
        "plt.yticks([50,60,70,80,90,100])\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "plt.gca().yaxis.set_label_coords(-0.06, 0.5) \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_values = [1, 5, 10, 25]\n",
        "auprc_values = {\n",
        "    \"SSL-RForest\": ([80.56,93.49,96.17,97.69]),\n",
        "    \"SL-RForest\": ([76.32,91.64,94.19,96.13]),\n",
        "    \"SSL-PCT\": ([61.37, 74.61, 79.02, 83.80]),\n",
        "    \"SL-PCT\": ([55.73, 70.46, 71.96, 78.21])\n",
        "}\n",
        "\n",
        "styles = {\n",
        "    \"SSL-RForest\": (\"black\", \"d\", \"-.\"),\n",
        "    \"SL-RForest\": (\"blue\", \"*\", \"-.\"),\n",
        "    \"SSL-PCT\": (\"green\", \"o\", \"-.\"),\n",
        "    \"SL-PCT\": (\"red\", \"s\", \"-.\")\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "for key, means in auprc_values.items():\n",
        "    color, marker, linestyle = styles[key]\n",
        "    plt.errorbar(N_values, means, fmt=marker, linestyle=linestyle, \n",
        "                 color=color, capsize=3, label=key)\n",
        "\n",
        "plt.title(\"DFC-15 (MLC), ResNet50\")\n",
        "plt.xlabel(\"N (%)\", fontsize=12)\n",
        "plt.ylabel(\"AUPRC\", fontsize=12)\n",
        "plt.xticks(N_values)\n",
        "plt.yticks([50,60,70,80,90,100])\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "plt.gca().yaxis.set_label_coords(-0.10, 0.5) \n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_values = [1, 5, 10, 25]\n",
        "auprc_values = {\n",
        "    \"SSL-RForest\": ([31.81, 80.11, 91.98, 92.32]),\n",
        "    \"SL-RForest\": ([28.89, 66.54, 89.23, 91.12]),\n",
        "    \"SSL-PCT\": ([11.38, 42.78, 51.66, 58.22]),\n",
        "    \"SL-PCT\": ([5.63, 20.37, 31.56, 55.43])\n",
        "}\n",
        "\n",
        "styles = {\n",
        "    \"SSL-RForest\": (\"black\", \"d\", \"-.\"),\n",
        "    \"SL-RForest\": (\"blue\", \"*\", \"-.\"),\n",
        "    \"SSL-PCT\": (\"green\", \"o\", \"-.\"),\n",
        "    \"SL-PCT\": (\"red\", \"s\", \"-.\")\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "for key, means in auprc_values.items():\n",
        "    color, marker, linestyle = styles[key]\n",
        "    plt.errorbar(N_values, means, fmt=marker, linestyle=linestyle, \n",
        "                 color=color, capsize=3, label=key)\n",
        "\n",
        "plt.title(\"OPTIMAL-31 (MCC), ResNet50\")\n",
        "plt.xlabel(\"N (%)\", fontsize=12)\n",
        "plt.ylabel(\"AUPRC\", fontsize=12)\n",
        "plt.xticks(N_values)\n",
        "plt.yticks([0,20,40,60,80,100])\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "plt.gca().yaxis.set_label_coords(-0.10, 0.5) \n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_values = [1, 5, 10, 25]\n",
        "auprc_values = {\n",
        "    \"SSL-RForest\": ([34.49, 84.26, 92.38, 93.57]),\n",
        "    \"SL-RForest\": ([31.47, 74.19, 90.11, 91.96]),\n",
        "    \"SSL-PCT\": ([13.78, 47.87, 63.16, 64.37]),\n",
        "    \"SL-PCT\": ([5.77, 17.89, 38.50, 57.44])\n",
        "}\n",
        "\n",
        "styles = {\n",
        "    \"SSL-RForest\": (\"black\", \"d\", \"-.\"),\n",
        "    \"SL-RForest\": (\"blue\", \"*\", \"-.\"),\n",
        "    \"SSL-PCT\": (\"green\", \"o\", \"-.\"),\n",
        "    \"SL-PCT\": (\"red\", \"s\", \"-.\")\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(7, 3.5))\n",
        "for key, means in auprc_values.items():\n",
        "    color, marker, linestyle = styles[key]\n",
        "    plt.errorbar(N_values, means, fmt=marker, linestyle=linestyle, \n",
        "                 color=color, capsize=3, label=key)\n",
        "\n",
        "plt.title(\"OPTIMAL-31 (MCC), EfficientNetB2\")\n",
        "plt.xlabel(\"N (%)\", fontsize=12)\n",
        "plt.ylabel(\"AUPRC\", fontsize=12)\n",
        "plt.xticks(N_values)\n",
        "plt.yticks([0,20,40,60,80,100])\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "plt.gca().yaxis.set_label_coords(-0.06, 0.5) \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "w_values = np.arange(0, 1.1, 0.1)\n",
        "mean_scores = [0.35, 0.48, 0.69, 0.71, 0.82, 0.81, 0.77, 0.79, 0.69, 0.63, 0.59]\n",
        "\n",
        "best_idx = np.argmax(mean_scores)\n",
        "best_w = w_values[best_idx]\n",
        "best_score = mean_scores[best_idx]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(w_values, mean_scores, marker='o', label='Mean Score')\n",
        "plt.axvline(best_w, color='r', linestyle='--', label=f'Best w = {best_w:.1f}')\n",
        "plt.xlabel('w')\n",
        "plt.ylabel('Mean Score')\n",
        "plt.title('w vs Mean Score')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
